# 项目介绍
**项目地址**
https://github.com/onenewcode/learning-lm-rs

## f16 模型转换
该代码位于分支**f16**中，该分支的代码，将f32模型转换成f16模型，并实现了基本的推理功能。

### 技术介绍
- 模型转换方面，使用了transformers框架，把基本的f32模型转换成f16模型。
- f16方面，未使用第三方的half库，而是使用了一些非稳定特性，由于官方未实现部分迭代器的方法，需要自己手动实现

## 单机模型
### 功能介绍
- 会话切换
- 单机会话
- 会话回滚
- 支持异步输出
- 支持加载半精度模型(由于技术原因，存在部分硬编码，需要手动改)

### 技术介绍
**类型支持**
为了同时支持两种不同的类型，半精度方面采用了第三方库half，同时为了完成float的抽象，引入了第三方库num-traits，用来实现不同类型的抽象。
**异步输出**
同时为了支持异步输出，采用了tokio的异步编程，在推理的时候，会单独生成一个阻塞线程用于推理，用管道作为不同线程之间进行通信的方式，这样使程序可以异步的输出在控制台。
**缓存管理**
缓存管理使用为了初始化全局的变量，这里使用了非稳定的OnceLock结构，从而减少对外部的依赖。同时缓存是map结构，以用户的sessionid为key，value中存储了本次会话推理的长度，推理的历史数据用于实现会话回滚。

# 使用介绍
首先拉去代码，建议直使用chat_new分支下面的代码。如果使用的是vscode可以可以直接使用.vascode文件，经行debug运行。
当然也可以通过以下的命令行运行我们的单机对话 
>cargo run chat --model D:\project\rust\learning-lm-rs\models\chat

--model 后面是模型文件的路径，以上命令也是在也是在文件根目录下运行的


## 效果展示
**对话界面**
![alt text](image/image.png)

我们可以在对话界面输入任意的对话内容，对话界面会首先输出我们当前对话的id，如图所框，接下来便会异步的输出我们的对话内容。

**对话切换**
